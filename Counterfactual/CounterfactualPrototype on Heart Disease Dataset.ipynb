{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CounterfactualPrototype on Heart Disease Dataset.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JvejsoLJkOTQ"
      },
      "source": [
        "# Counterfactuals Guided by Prototypes for Heart Disease dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Luf0ukAUd4W",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0cc455d4-18bd-429d-85f2-ebd344cd8b49"
      },
      "source": [
        "!pip install alibi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting alibi\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/89/c1/7e6bbb4a69d84063d84dbf39ef5f95d9ee230379c542bed4e44ca8b878d8/alibi-0.5.5-py3-none-any.whl (228kB)\n",
            "\r\u001b[K     |█▍                              | 10kB 17.2MB/s eta 0:00:01\r\u001b[K     |██▉                             | 20kB 1.7MB/s eta 0:00:01\r\u001b[K     |████▎                           | 30kB 2.2MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 40kB 2.5MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 51kB 2.0MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 61kB 2.3MB/s eta 0:00:01\r\u001b[K     |██████████                      | 71kB 2.4MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 81kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 92kB 2.9MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 102kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 112kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 122kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 133kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 143kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 153kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 163kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 174kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 184kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 194kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 204kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 215kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 225kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 235kB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from alibi) (1.1.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from alibi) (0.22.2.post1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from alibi) (1.18.5)\n",
            "Requirement already satisfied: scikit-image!=0.17.1 in /usr/local/lib/python3.6/dist-packages (from alibi) (0.16.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from alibi) (1.4.1)\n",
            "Requirement already satisfied: tensorflow>=2.0 in /usr/local/lib/python3.6/dist-packages (from alibi) (2.3.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from alibi) (3.2.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.2 in /usr/local/lib/python3.6/dist-packages (from alibi) (3.7.4.3)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.6/dist-packages (from alibi) (4.6.3)\n",
            "Collecting shap>=0.36\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d2/17/37ee6c79cafbd9bb7423b54e55ea90beec66aa7638664d607bcc28de0bae/shap-0.36.0.tar.gz (319kB)\n",
            "\u001b[K     |████████████████████████████████| 327kB 8.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from alibi) (2.23.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from alibi) (7.0.0)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.6/dist-packages (from alibi) (20.2.0)\n",
            "Requirement already satisfied: spacy[lookups] in /usr/local/lib/python3.6/dist-packages (from alibi) (2.2.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas->alibi) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->alibi) (2018.9)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->alibi) (0.16.0)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image!=0.17.1->alibi) (2.4.1)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image!=0.17.1->alibi) (2.5)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image!=0.17.1->alibi) (1.1.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.4.0,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.0->alibi) (2.3.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.0->alibi) (1.1.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.0->alibi) (3.12.4)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.0->alibi) (1.32.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.0->alibi) (3.3.0)\n",
            "Requirement already satisfied: tensorboard<3,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.0->alibi) (2.3.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.0->alibi) (1.12.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.0->alibi) (0.35.1)\n",
            "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.0->alibi) (2.10.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.0->alibi) (1.15.0)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.0->alibi) (1.6.3)\n",
            "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.0->alibi) (1.1.2)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.0->alibi) (0.3.3)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.0->alibi) (0.2.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.0->alibi) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->alibi) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->alibi) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->alibi) (2.4.7)\n",
            "Requirement already satisfied: tqdm>4.25.0 in /usr/local/lib/python3.6/dist-packages (from shap>=0.36->alibi) (4.41.1)\n",
            "Collecting slicer\n",
            "  Downloading https://files.pythonhosted.org/packages/46/cf/f37ac7f61214ed044b0df91252ab19376de5587926c5b572f060eb7bf257/slicer-0.0.4-py3-none-any.whl\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.6/dist-packages (from shap>=0.36->alibi) (0.48.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->alibi) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->alibi) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->alibi) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->alibi) (2.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy[lookups]->alibi) (2.0.3)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy[lookups]->alibi) (1.0.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy[lookups]->alibi) (1.0.2)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy[lookups]->alibi) (0.4.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy[lookups]->alibi) (50.3.0)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy[lookups]->alibi) (7.4.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy[lookups]->alibi) (1.0.2)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy[lookups]->alibi) (3.0.2)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy[lookups]->alibi) (0.8.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy[lookups]->alibi) (1.1.3)\n",
            "Collecting spacy-lookups-data<0.2.0,>=0.0.5; extra == \"lookups\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/3c/4a37ca7d0c21dc2287a8bb5d249f5f3211cdf3d598acf742bf5bb8c87169/spacy_lookups_data-0.1.0.tar.gz (28.0MB)\n",
            "\u001b[K     |████████████████████████████████| 28.0MB 144kB/s \n",
            "\u001b[?25hRequirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.0->scikit-image!=0.17.1->alibi) (4.4.2)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow>=2.0->alibi) (1.7.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow>=2.0->alibi) (3.2.2)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow>=2.0->alibi) (1.17.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow>=2.0->alibi) (0.4.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow>=2.0->alibi) (1.0.1)\n",
            "Requirement already satisfied: llvmlite<0.32.0,>=0.31.0dev0 in /usr/local/lib/python3.6/dist-packages (from numba->shap>=0.36->alibi) (0.31.0)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy[lookups]->alibi) (2.0.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow>=2.0->alibi) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow>=2.0->alibi) (4.6)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow>=2.0->alibi) (4.1.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow>=2.0->alibi) (1.3.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy[lookups]->alibi) (3.2.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow>=2.0->alibi) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow>=2.0->alibi) (3.1.0)\n",
            "Building wheels for collected packages: shap, spacy-lookups-data\n",
            "  Building wheel for shap (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for shap: filename=shap-0.36.0-cp36-cp36m-linux_x86_64.whl size=456465 sha256=16fc242529ab5a271805a1fc3c6d0d68f8d166399d2218e9ff068c53b94614fe\n",
            "  Stored in directory: /root/.cache/pip/wheels/fb/15/e1/8f61106790da27e0765aaa6e664550ca2c50ea339099e799f4\n",
            "  Building wheel for spacy-lookups-data (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for spacy-lookups-data: filename=spacy_lookups_data-0.1.0-py2.py3-none-any.whl size=28052144 sha256=5ea973bda890c380136c409c718d4b2099b1c18a0af0af5c3ef35a3aa2a9e34e\n",
            "  Stored in directory: /root/.cache/pip/wheels/2a/2b/0a/d6fb6235c56d014d224bca760d15d7cbdd820813085ffcd35d\n",
            "Successfully built shap spacy-lookups-data\n",
            "Installing collected packages: slicer, shap, alibi, spacy-lookups-data\n",
            "Successfully installed alibi-0.5.5 shap-0.36.0 slicer-0.0.4 spacy-lookups-data-0.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HmpVzmVVUid3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "fccc0ecc-6ec4-4cb7-8f33-e05ac7495554"
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.get_logger().setLevel(40) # suppress deprecation messages\n",
        "tf.compat.v1.disable_v2_behavior() # disable TF2 behaviour as alibi code still relies on TF1 constructs\n",
        "from tensorflow.keras.layers import Dense, Input\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import matplotlib\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from alibi.explainers import CounterFactualProto\n",
        "\n",
        "print('TF version: ', tf.__version__)\n",
        "print('Eager execution enabled: ', tf.executing_eagerly()) # False"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TF version:  2.3.0\n",
            "Eager execution enabled:  False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aFrdQQBKU-Bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "7eeb2715-0b58-4858-fd52-6aacff90c92c"
      },
      "source": [
        "df = pd.read_csv('/content/heartu.csv')\n",
        "df.head(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>cp</th>\n",
              "      <th>trestbps</th>\n",
              "      <th>chol</th>\n",
              "      <th>fbs</th>\n",
              "      <th>restecg</th>\n",
              "      <th>thalach</th>\n",
              "      <th>exang</th>\n",
              "      <th>oldpeak</th>\n",
              "      <th>slope</th>\n",
              "      <th>ca</th>\n",
              "      <th>thal</th>\n",
              "      <th>condition</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>69</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>160</td>\n",
              "      <td>234</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>131</td>\n",
              "      <td>0</td>\n",
              "      <td>0.1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>69</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>140</td>\n",
              "      <td>239</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>151</td>\n",
              "      <td>0</td>\n",
              "      <td>1.8</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>66</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>150</td>\n",
              "      <td>226</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>114</td>\n",
              "      <td>0</td>\n",
              "      <td>2.6</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>65</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>138</td>\n",
              "      <td>282</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>174</td>\n",
              "      <td>0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>64</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>110</td>\n",
              "      <td>211</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>144</td>\n",
              "      <td>1</td>\n",
              "      <td>1.8</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   age  sex  cp  trestbps  chol  ...  oldpeak  slope  ca  thal  condition\n",
              "0   69    1   0       160   234  ...      0.1      1   1     0          0\n",
              "1   69    0   0       140   239  ...      1.8      0   2     0          0\n",
              "2   66    0   0       150   226  ...      2.6      2   0     0          0\n",
              "3   65    1   0       138   282  ...      1.4      1   1     0          1\n",
              "4   64    1   0       110   211  ...      1.8      1   0     0          0\n",
              "\n",
              "[5 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJfdoak4VKIt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8f1e596b-11ca-48b0-92be-7aacbd506317"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(297, 14)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wU0-cgh-VMBe"
      },
      "source": [
        "feature_names=['age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', 'thalach', 'exang', 'oldpeak', 'slope', 'ca', 'thal']\n",
        "data = df[feature_names]\n",
        "target = df.condition"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dBcz8Z7jkbw2"
      },
      "source": [
        "Standardizing the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gooViOk9Vzhu"
      },
      "source": [
        "mu = data.mean(axis=0)\n",
        "sigma = data.std(axis=0)\n",
        "data = (data - mu) / sigma"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tlfAsohRkfKb"
      },
      "source": [
        "Splitting the data into training and testing set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-1YR5j2WSVE"
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(data,target, random_state=0)\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R8qVRrr9kmHp"
      },
      "source": [
        "Seeding a single counterfactual value for the runtime"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ywPUk6IAWk-9"
      },
      "source": [
        "np.random.seed(0)\n",
        "tf.random.set_seed(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YWuLk3OmWmxX"
      },
      "source": [
        "def nn_model():\n",
        "    x_in = Input(shape=(13,))\n",
        "    x = Dense(40, activation='relu')(x_in)\n",
        "    x = Dense(40, activation='relu')(x)\n",
        "    x_out = Dense(2, activation='softmax')(x)\n",
        "    nn = Model(inputs=x_in, outputs=x_out)\n",
        "    nn.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
        "    return nn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F29F8INdks7-"
      },
      "source": [
        "Applying a neural network model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L5Y7Uo4VWpJ0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "42af5831-f120-4478-b76a-9169475166e8"
      },
      "source": [
        "nn = nn_model()\n",
        "nn.summary()\n",
        "nn.fit(x_train, y_train, batch_size=64, epochs=500, verbose=0)\n",
        "nn.save('nn_heart.h5', save_format='h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 13)]              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 40)                560       \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 40)                1640      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 2)                 82        \n",
            "=================================================================\n",
            "Total params: 2,282\n",
            "Trainable params: 2,282\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pFnS_cm7WsLK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "874c9bb1-0f35-4cd9-a0da-ef12d6a0b5a1"
      },
      "source": [
        "nn = load_model('nn_heart.h5')\n",
        "score = nn.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test accuracy: ', score[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test accuracy:  0.82666665\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r1FDch05kzFS"
      },
      "source": [
        "We can see that the test accuracy is 82.67%, which is not too bad"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fRhWrbbeaN1T"
      },
      "source": [
        "x_test=x_test.to_numpy()\n",
        "x_train=x_train.to_numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XHlaCE4Lk7ND"
      },
      "source": [
        "Taking an instance for obtaining its counterfactual"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "udDZEdSsW07X",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fe1ba6b9-39ef-4228-870b-4fdbffb33c03"
      },
      "source": [
        "X = x_test[3].reshape((1,) + x_test[3].shape)\n",
        "shape = X.shape\n",
        "shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 13)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gGCBnYozW9p1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9e5af86b-e576-4f34-97d2-606f17a77666"
      },
      "source": [
        "nn = load_model('nn_heart.h5')\n",
        "\n",
        "# Here we use k-d trees for reprenting the class prototypes\n",
        "cf = CounterFactualProto(nn, shape, use_kdtree=True, theta=10., max_iterations=1000,\n",
        "                         feature_range=(x_train.min(axis=0), x_train.max(axis=0)),\n",
        "                         c_init=1., c_steps=10)\n",
        "\n",
        "cf.fit(x_train)\n",
        "explanation = cf.explain(X)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No encoder specified. Using k-d trees to represent class prototypes.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nl5Pua0mXep8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        },
        "outputId": "0ec4bce1-a859-4179-ba68-be91fe2afb43"
      },
      "source": [
        "print('Original prediction: {}'.format(explanation.orig_class))\n",
        "print('Counterfactual prediction: {}'.format(explanation.cf['class']))\n",
        "#print(explanation.cf['proba'])\n",
        "sigma=sigma.to_numpy()\n",
        "mu=mu.to_numpy()\n",
        "orig = X * sigma + mu\n",
        "counterfactual = explanation.cf['X'] * sigma + mu\n",
        "delta = counterfactual - orig\n",
        "for i, f in enumerate(feature_names):\n",
        "    if np.abs(delta[0][i]) > 1e-4:\n",
        "      print('{}: {}'.format(f, delta[0][i]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original prediction: 1\n",
            "Counterfactual prediction: 0\n",
            "cp: -0.8131889454245802\n",
            "trestbps: -20.180294808502538\n",
            "thalach: 7.900992597841537\n",
            "oldpeak: -1.798546826159645\n",
            "ca: -1.8905086346674485\n",
            "thal: -0.44745449912977175\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ttCXWTdurtay"
      },
      "source": [
        "Here we see that the original prediction is 1 (Disease), we apply the counterfactual explanations to change the condition from disease to No Disease.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JeTwPWVGY8nM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uLVPkJ-_sigK"
      },
      "source": [
        "Here, we see that the chest pain type should be decrease by ```|floor(-0.813)| = 1``` i.e the chest pain should belong to recognizable\n",
        "(symptomatic) category. Also, the resting blood pressure should be low. The maximum heart rate of the person should be higher by around 8, which can be done by regular exercise. Old peak value should be lowered by having a dash diet. ca should also be reduced by ```|floor(-1.89)| = 2``` by detecting the blockage using angioplasty and doing a bypass surgery if needed. \n",
        "\n"
      ]
    }
  ]
}